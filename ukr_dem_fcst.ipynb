{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to pull data from systradingmarketdata\n",
    "\n",
    "def get_marketdata(start_datetime, end_datetime, analysis_group):\n",
    "    #define the basic parameters of the API call\n",
    "    baseurl = \"https://systradingmarketdataapi.azurewebsites.net/api/\"\n",
    "    url = f\"{baseurl}Authentication/request\"\n",
    "    \n",
    "    payload=f'{{\"username\": \"{os.getenv(\"MARKETDATA_USER\")}\", \"password\": \"{os.getenv(\"MARKETDATA_PWD\")}\"}}'\n",
    "    headers = {\n",
    "      'Authorization': '',\n",
    "      'Content-Type': 'application/json',\n",
    "    }\n",
    "    \n",
    "    # get the token\n",
    "    login_response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    \n",
    "    params = f\"start={start_datetime}&end={end_datetime}&granularity=hours&timeZone=GMT\"\n",
    "    #analysis_group = \"1Base_EC%20Generation%20by%20Fuel%20Type\"\n",
    "    group_url = f'{baseurl}AnalysisGroup/AllCurves/{analysis_group}?{params}'\n",
    "\n",
    "    payload={}\n",
    "    headers = {\n",
    "      'Authorization': f'Bearer {login_response.text}',\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", group_url, headers=headers, data=payload)\n",
    "\n",
    "    #print out the json\n",
    "    #print(response.text)\n",
    "    # %%\n",
    "\n",
    "    power_json = json.loads(response.text)\n",
    "\n",
    "    # loading hour sequence from the maximum and minimum found - it's not yet clear\n",
    "    # the logic for the cut off date times.\n",
    "    max_found_time = max([x['timeSeries'][-1]['date'] for x in power_json['curves']])\n",
    "    min_found_time = min([x['timeSeries'][0]['date'] for x in power_json['curves']])\n",
    "\n",
    "    hour_sequence = pd.date_range(start = pd.to_datetime(min_found_time),\n",
    "                             end = pd.to_datetime(max_found_time),\n",
    "                             freq = \"H\")\n",
    "    # %%\n",
    "    # create named dataframe from json\n",
    "    def turn_series_to_df(json_series):\n",
    "        this_df = pd.DataFrame.from_records(json_series['timeSeries'])\n",
    "        this_df['date'] = pd.to_datetime(this_df['date'])\n",
    "        this_df.set_index('date', inplace=True)\n",
    "        this_df.rename(columns={'value' : json_series['memberName']}, inplace=True)#'name' is an alternative here to memberName\n",
    "        return(this_df)\n",
    "\n",
    "    # %%\n",
    "    # load initial dataset for first time series and fill mising hours\n",
    "\n",
    "    power_df = turn_series_to_df(power_json['curves'][0])\n",
    "    power_df = power_df.reindex(hour_sequence)\n",
    "    power_df.rename_axis(\"date\", axis='index', inplace=True)\n",
    "\n",
    "    # %%\n",
    "\n",
    "    for full_series in power_json['curves'][1:]:\n",
    "        this_df = turn_series_to_df(full_series)\n",
    "        power_df = pd.merge(power_df,this_df,how='left', left_index=True, right_index=True)\n",
    "\n",
    "    return power_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the data and produce the forecast\n",
    "\n",
    "dt14 = datetime.today() + timedelta(days = 15)\n",
    "dt14=datetime(dt14.year,dt14.month,dt14.day)\n",
    "\n",
    "ce = get_marketdata(datetime(2021,10,1), dt14, 'weather_CEE')\n",
    "\n",
    "\n",
    "ce = ce.resample(rule='24H', closed='left', label='left', base=5).mean().round(1)\n",
    "ce['date'] = ce.apply(lambda x: datetime(x.name.year, x.name.month, x.name.day), axis = 1)\n",
    "ce = ce.set_index('date')\n",
    "ce = ce.rename(columns = {ce.columns[0]:'obs_Kyiv', ce.columns[1]:'fcst_Kyiv'})\n",
    "#ce = ce.set_index['date']\n",
    "\n",
    "comp = pd.DataFrame(index =pd.date_range(start = datetime.today(), end = dt14+ timedelta(days =-1)), columns = ['FCST'])\n",
    "comp = comp.resample('D').last()\n",
    "comp['FCST'] = comp.apply(lambda x: ce['fcst_Kyiv'][ce.index==x.name].iloc[0], axis = 1) # if ((x.name >= datetime.today()) & ((x.name - datetime.today()).days<14)) else np.nan\n",
    "\n",
    "coefs = pd.read_csv('coef.csv')\n",
    "slope = coefs['slope'].iloc[0]\n",
    "inter = coefs['intercept'].iloc[0]\n",
    "\n",
    "comp['DEM_FCST'] = comp['FCST'] * slope  + inter + 3.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the output in the folder\n",
    "#!!! This part needs to be re-written as the output should be saved in the database\n",
    "comp.to_csv('output/forecast_'+datetime.today().strftime(\"%Y-%m-%d\")+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare with the previous forecast\n",
    "\n",
    "#!!! this part should be re-written as we should pull the previous forecast from the database\n",
    "prevdate = datetime.now()+timedelta(days = -3) if datetime.today().weekday() == 0 else datetime.now()+timedelta(days = -1)\n",
    "prevforecast = pd.read_csv('output/forecast_'+prevdate.strftime(\"%Y-%m-%d\")+'.csv', index_col =0)\n",
    "prevforecast.index = pd.to_datetime(prevforecast.index)\n",
    "#prevdate = datetime(prevdate.year, prevdate.month, prevdate.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate day-on-day change\n",
    "dod = pd.DataFrame((prevforecast['DEM_FCST']-comp['DEM_FCST']).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day-on-day change:\n",
      "            DEM_FCST\n",
      "2021-12-20      -1.0\n",
      "2021-12-21      -8.0\n",
      "2021-12-22      -9.0\n",
      "2021-12-23      -9.0\n",
      "2021-12-24      -5.0\n",
      "2021-12-25      -2.0\n",
      "2021-12-26      -1.0\n",
      "2021-12-27      -0.0\n",
      "2021-12-28       0.0\n",
      "2021-12-29      -1.0\n",
      "2021-12-30      -2.0\n",
      "Current forecast:\n",
      "2021-12-20    116.0\n",
      "2021-12-21    122.5\n",
      "2021-12-22    124.4\n",
      "2021-12-23    123.6\n",
      "2021-12-24    119.9\n",
      "2021-12-25    117.5\n",
      "2021-12-26    116.4\n",
      "2021-12-27    115.2\n",
      "2021-12-28    114.8\n",
      "2021-12-29    115.6\n",
      "2021-12-30    117.1\n",
      "2021-12-31    118.3\n",
      "2022-01-01    119.5\n",
      "2022-01-02    120.1\n",
      "Freq: D, Name: DEM_FCST, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Print the results (we should add this to our daily emails)\n",
    "print('Day-on-day change:')\n",
    "print(dod.round())\n",
    "\n",
    "print('Current forecast:')\n",
    "print(comp['DEM_FCST'].round(1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c773e69d5e6e93a97672e0b8d092dd8a845c457d11be5963434f5fb97cbc8e8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('newenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
